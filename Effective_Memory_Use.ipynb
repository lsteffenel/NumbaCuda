{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Effective+Memory+Use.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/NumbaCuda/blob/main/Effective_Memory_Use.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Avant de commencer\n",
        "L'exécution de ces notebooks sur Colab nécessite deux choses (au 4/2/2025) :\n",
        "\n",
        "1. des resources GPU\n",
        "  * Menu \"Exécution\" -> \"Modifier le type d'exécution\"\n",
        "2. D'utiliser une version plus ancienne de Colab en raison de certaines incompatibilités du pilote Nvidia\n",
        "  * Connecter l'environnement d'exécution\n",
        "  * Menu \"Outils\" -> \"Pallette de commandes\". Cherchez \"version\" dans la barre et sélectionnez l'option \"Utiliser la version d'environnement d'exécution de remplacement\"\n"
      ],
      "metadata": {
        "id": "qcfzgaA2mW7U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVtAcH6Q0Mna"
      },
      "source": [
        "# Utilisation efficace du sous-système de mémoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpyt3gzT0Mnb"
      },
      "source": [
        "Maintenant que vous savez écrire des noyaux CUDA  et que vous comprenez l'importance de lancer des grilles pour donner suffisamment de travail au GPU afin de masquer la latence, vous allez apprendre des techniques pour utiliser efficacement la mémoire du GPU. Ces techniques sont largement applicables à une variété d'applications CUDA et sont parmi les plus importantes lorsqu'il s'agit d'accélérer votre code CUDA.\n",
        "\n",
        "Vous allez commencer par en apprendre davantage sur la coalescence de mémoire (regroupement/organisation de blocs mémoire). Pour tester votre capacité à raisonner sur la coalescence, vous découvrirez ensuite les grilles bidimensionnelles et les blocs de threads. Ensuite, vous découvrirez comment utiliser la mémoire partagée, qui sera utilisée pour faciliter la coalescence là où cela n'aurait pas été possible autrement. Enfin, vous découvrirez les conflits qui peuvent arriver avec la mémoire partagée et une technique pour les résoudre.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3GIL0le0Mnd"
      },
      "source": [
        "## Le problème : l'accès \"éparpillé\" à la mémoire nuit les performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loksj-jY0Mnd"
      },
      "source": [
        "Avant d’apprendre les détails sur la coalescence, exécutez les cellules suivantes pour observer les implications en termes de performances d’un changement apparemment trivial du mode d’accès aux données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--TayTTy0Mnd"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rMOxcJrS0Mne"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DchcEDY10Mng"
      },
      "source": [
        "### Data Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbUfmnzj0Mng"
      },
      "source": [
        "Dans cette cellule, nous définissons `n` et créons une grille avec `n` threads. Nous créons également un vecteur de sortie de longueur `n`. Pour les entrées, nous créons des vecteurs de taille `stride * n` pour des raisons qui seront expliquées ci-dessous :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sSIYp-Rl0Mnh"
      },
      "source": [
        "n = 1024*1024 # 1M\n",
        "\n",
        "threads_per_block = 1024\n",
        "blocks = int(n / threads_per_block)\n",
        "\n",
        "stride = 16\n",
        "\n",
        "# Input Vectors of length stride * n\n",
        "a = np.ones(stride * n).astype(np.float32)\n",
        "b = a.copy().astype(np.float32)\n",
        "\n",
        "# Output Vector\n",
        "out = np.zeros(n).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_b = cuda.to_device(b)\n",
        "d_out = cuda.to_device(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuktrimW0Mnh"
      },
      "source": [
        "### Kernel Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0JmJ9l60Mnh"
      },
      "source": [
        "Dans `add_experiment`, chaque thread de la grille ajoutera un élément dans `a` et un élément dans `b` puis écrira le résultat dans `out`. Le noyau a été écrit de telle sorte que nous puissions passer une valeur `coalesced` de `True` ou `False` pour affecter la façon dont il indexe dans les vecteurs `a` et `b`. Vous verrez la comparaison des performances des deux modes ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "J1pNj0RP0Mni"
      },
      "source": [
        "@cuda.jit\n",
        "def add_experiment(a, b, out, stride, coalesced):\n",
        "    i = cuda.grid(1)\n",
        "    # The above line is equivalent to\n",
        "    # i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    if coalesced == True:\n",
        "        out[i] = a[i] + b[i]\n",
        "    else:\n",
        "        out[i] = a[stride*i] + b[stride*i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tov38eY0Mni"
      },
      "source": [
        "### Lancement d'un kernet avec un accès \"coalesced\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EzN1lvF0Mnj"
      },
      "source": [
        "Ici, nous passons « True » comme valeur « coalesced » et observons les performances du noyau sur plusieurs exécutions :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "qP_h6zzm0Mnj"
      },
      "source": [
        "%timeit add_experiment[blocks, threads_per_block](d_a, d_b, d_out, stride, True); cuda.synchronize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94KnxXDH0Mnj"
      },
      "source": [
        "Vérifions si le noyau s'exécute comme attendu :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "E7ilWl6D0Mnk"
      },
      "source": [
        "result = d_out.copy_to_host()\n",
        "truth = a[:n] + b[:n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "9U02BdKP0Mnk"
      },
      "source": [
        "np.array_equal(result, truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkMjgEWq0Mnk"
      },
      "source": [
        "### Lancement d'un noyau sans accès coalescent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYiuF8ZR0Mnk"
      },
      "source": [
        "Dans cette cellule, nous passons \" False \" pour observer les performances du modèle d'accès aux données non coalescents :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HY9oGSDt0Mnl"
      },
      "source": [
        "%timeit add_experiment[blocks, threads_per_block](d_a, d_b, d_out, stride, False); cuda.synchronize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VodDON60Mnl"
      },
      "source": [
        "Vérifions si le noyau s'exécute comme attendu :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "e4yAsZOD0Mnl"
      },
      "source": [
        "result = d_out.copy_to_host()\n",
        "truth = a[::stride] + b[::stride]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "UgxF3vkt0Mnl"
      },
      "source": [
        "np.array_equal(result, truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6K4dg590Mnl"
      },
      "source": [
        "### Résultats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVKtxTET0Mnm"
      },
      "source": [
        "Les performances du mode d'accès \"non coalescent\" sont bien pires. Vous allez maintenant découvrir pourquoi et comment réfléchir aux modes d'accès aux données pour obtenir des noyaux très performants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y7yB1vg0Mnm"
      },
      "source": [
        "## Présentation : Global Memory Coalescing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV0LZIyR0Mnm"
      },
      "source": [
        "Regardez la présentation ci-dessous :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7PYWV1wY0Mnm"
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame('https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-02-V1/coalescing-v3.pptx', 800, 450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEVtOBbR0Mnm"
      },
      "source": [
        "## Exercice : Somme des Colonnes et Lignes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBhLKf6u0Mnn"
      },
      "source": [
        "Pour cet exercice, il vous sera demandé d'écrire un noyau pour faire la somme des colonnes, utilisant le mode d'accès mémoire coalescés. Pour commencer, vous observerez les performances sans ce mode d' accès mémoire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa9jRAJI0Mnn"
      },
      "source": [
        "### Somme des lignes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-bKCcyD0Mnn"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yIVrXcGn0Mnn"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDlkLI2p0Mnn"
      },
      "source": [
        "**Data Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQL4dpWq0Mnn"
      },
      "source": [
        "Dans ce paragraphe nous créons une matrice pour l'entrée ainsi qu'un vecteur pour stocker la solution, et nous transférons chacun d'eux vers le périphérique. Nous définissons également les dimensions de la grille et du bloc à utiliser lorsque nous lançons le noyau.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Sou7fNbf0Mno"
      },
      "source": [
        "n = 16384 # matrix side size\n",
        "threads_per_block = 256\n",
        "blocks = int(n / threads_per_block)\n",
        "\n",
        "# Input Matrix\n",
        "a = np.ones(n*n).reshape(n, n).astype(np.float32)\n",
        "# Here we set an arbitrary row to an arbitrary value to facilitate a check for correctness below.\n",
        "a[3] = 9\n",
        "\n",
        "# Output vector\n",
        "sums = np.zeros(n).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_sums = cuda.to_device(sums)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQYPTiQT0Mno"
      },
      "source": [
        "**Le noyau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xibILyND0Mno"
      },
      "source": [
        "`row_sums` utilisera chaque thread pour parcourir une ligne de données, effectuer la somme, puis stockera la somme des lignes dans `sums`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "67woR5pO0Mno"
      },
      "source": [
        "@cuda.jit\n",
        "def row_sums(a, sums, n):\n",
        "    idx = cuda.grid(1)\n",
        "    sum = 0.0\n",
        "\n",
        "    for i in range(n):\n",
        "        # Each thread will sum a row of `a`\n",
        "        sum += a[idx][i]\n",
        "\n",
        "    sums[idx] = sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee57AO4_0Mno"
      },
      "source": [
        "**Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TZS_9bfZ0Mno"
      },
      "source": [
        "%timeit row_sums[blocks, threads_per_block](d_a, d_sums, n); cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLicTRw0Mnp"
      },
      "source": [
        "**Vérification du résultat**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rUsKLQMi0Mnp"
      },
      "source": [
        "result = d_sums.copy_to_host()\n",
        "truth = a.sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cajPu6xc0Mnp"
      },
      "source": [
        "np.array_equal(truth, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ofbySFG0Mnp"
      },
      "source": [
        "### Somme des colonnes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OckAKRIG0Mnp"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "HohrB1RC0Mnp"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJpUHYgy0Mnp"
      },
      "source": [
        "**Data Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eNsBt1w0Mnq"
      },
      "source": [
        "On reprend le même format précédent, mais avec des valeurs sur les colonnes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cemu8-A-0Mnq"
      },
      "source": [
        "n = 16384 # matrix side size\n",
        "threads_per_block = 256\n",
        "blocks = int(n / threads_per_block)\n",
        "\n",
        "a = np.ones(n*n).reshape(n, n).astype(np.float32)\n",
        "# Here we set an arbitrary column to an arbitrary value to facilitate a check for correctness below.\n",
        "a[:, 3] = 9\n",
        "sums = np.zeros(n).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_sums = cuda.to_device(sums)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vQMYSju0Mnq"
      },
      "source": [
        "**Définition du noyau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXuf1JVr0Mnq"
      },
      "source": [
        "`col_sums` utilisera chaque thread pour parcourir une colonne de données, en la sommant, puis stockera la somme de sa colonne dans `sums`. Complétez la définition du noyau pour y parvenir (c'est à vous de le faire 😀)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vSBaE_qy0Mnq"
      },
      "source": [
        "@cuda.jit\n",
        "def col_sums(a, sums, ds):\n",
        "    # TODO: Write this kernel to store the sum of each column in matrix `a` to the `sums` vector.\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i15Fke5q0Mnq"
      },
      "source": [
        "**Vérification de la Performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQgYMZx30Mnr"
      },
      "source": [
        "En supposant que vous ayez écrit `col_sums` pour utiliser l'accès coalescent, vous devriez voir une accélération significative (presque 2x) par rapport aux `row_sums` \"non coalescent\" que vous avez exécutés ci-dessus :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "f35hHNfm0Mnr"
      },
      "source": [
        "%timeit col_sums[blocks, threads_per_block](d_a, d_sums, n); cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfgNd_IL0Mnr"
      },
      "source": [
        "**Vérification des résultats**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIYJS3FY0Mnr"
      },
      "source": [
        "Confirm your kernel is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "y9qXj5Kl0Mnr"
      },
      "source": [
        "result = d_sums.copy_to_host()\n",
        "truth = a.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "7ytHoxap0Mnr"
      },
      "source": [
        "np.array_equal(truth, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY-RQRW10Mnr"
      },
      "source": [
        "## Des blocs et grilles à 2 et 3 dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bCiskf0Mns"
      },
      "source": [
        "Les grilles et les blocs peuvent être configurés pour contenir respectivement une collection bidimensionnelle ou tridimensionnelle de blocs ou de threads. Cela est fait principalement pour des raisons de commodité pour les programmeurs qui travaillent avec des données bidimensionnels ou tridimensionnels. Voici un exemple très simple pour mettre en évidence la syntaxe. Il faudra comprendre la définition du noyau et comme il est lancé pour que le concept n'ait un sens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MoYug8R90Mns"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rH9lgSHA0Mns"
      },
      "source": [
        "A = np.zeros((4,4)) # A 4x4 Matrix of 0's\n",
        "d_A = cuda.to_device(A)\n",
        "\n",
        "# Here we create a 2D grid with 4 blocks in a 2x2 structure, each with 4 threads in a 2x2 structure\n",
        "# by using a Python tuple to signify grid and block dimensions.\n",
        "blocks = (2, 2)\n",
        "threads_per_block = (2, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4kDlvZo0Mns"
      },
      "source": [
        "Ce noyau prendra une matrice d'entrée de 0 et écrira chacun de ses éléments directement dans la grille au format `X.Y`` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IxghwLch0Mns"
      },
      "source": [
        "@cuda.jit\n",
        "def get_2D_indices(A):\n",
        "    # By passing `2`, we get the thread's unique x and y coordinates in the 2D grid\n",
        "    x, y = cuda.grid(2)\n",
        "    # The above is equivalent to the following 2 lines of code:\n",
        "    # x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    # y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "\n",
        "    # Write the x index followed by a decimal and the y index.\n",
        "    A[x][y] = x + y / 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RZtWAc4c0Mns"
      },
      "source": [
        "get_2D_indices[blocks, threads_per_block](d_A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3Dytd6qd0Mnt"
      },
      "source": [
        "result = d_A.copy_to_host()\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNPnk2YL0Mnt"
      },
      "source": [
        "## Exercice : Somme de matrices 2D en mode coalescent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UytTSf790Mnt"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "SatpVW8U0Mnt"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CcT0xG90Mnt"
      },
      "source": [
        "### Data Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVciXU660Mnt"
      },
      "source": [
        "Dans cette cellule, nous définissons des matrices d'entrée d'éléments 2048x2048 `a` et `b`, ainsi qu'une matrice de sortie initialisée de 2048x2048. Nous copions ces matrices sur le GPU.\n",
        "\n",
        "Nous définissons également les dimensions de bloc et de grille à 2 dimensions. Notez que nous créons une grille avec le même nombre total de threads que d'éléments d'entrée et de sortie, de sorte que chaque thread de la grille calculera la somme pour un seul élément de la matrice de sortie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "q_TLDr1Z0Mnu"
      },
      "source": [
        "n = 2048*2048 # 4M\n",
        "\n",
        "# 2D blocks\n",
        "threads_per_block = (32, 32)\n",
        "# 2D grid\n",
        "blocks = (64, 64)\n",
        "\n",
        "# 2048x2048 input matrices\n",
        "a = np.arange(n).reshape(2048,2048).astype(np.float32)\n",
        "b = a.copy().astype(np.float32)\n",
        "\n",
        "# 2048x2048 0-initialized output matrix\n",
        "out = np.zeros_like(a).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_b = cuda.to_device(b)\n",
        "d_out = cuda.to_device(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eFw5ZJu0Mnu"
      },
      "source": [
        "### Somme pour une matrice 2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l05Yos500Mnu"
      },
      "source": [
        "Votre tâche consiste à compléter les tâches à effectuer dans `matrix_add` pour additionner correctement `a` et `b` dans `out`. Pour vous aider à comprendre les modes d'accès, `matrix_add` acceptera un booléen `coalesced` indiquant si les modèles d'accès doivent être coalescents ou non. Les deux modes (coalesced et uncoalesced) devraient produire des résultats corrects, cependant, vous devriez observer des accélérations significatives ci-dessous lors de l'exécution avec `coalesced` défini sur `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "V4uR7ezk0Mnu"
      },
      "source": [
        "@cuda.jit\n",
        "def matrix_add(a, b, out, coalesced):\n",
        "    # TODO: set x and y to index correctly such that each thread\n",
        "    # accesses one element in the data.\n",
        "    x, y = pass\n",
        "\n",
        "    if coalesced == True:\n",
        "        # TODO: write the sum of one element in `a` and `b` to `out`\n",
        "        # using a coalesced memory access pattern.\n",
        "    else:\n",
        "        # TODO: write the sum of one element in `a` and `b` to `out`\n",
        "        # using an uncoalesced memory access pattern."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMzVBdpm0Mnv"
      },
      "source": [
        "### Vérification de la performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wEdq7G50Mnv"
      },
      "source": [
        "Exécutez les deux cellules ci-dessous pour lancer `matrix_add` avec les modèles d'accès que vous avez écrits, et observez la différence de performances. Des cellules supplémentaires ont été fournies pour confirmer l'exactitude de votre noyau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMLqgTX30Mnv"
      },
      "source": [
        "**Coalesced**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OpvsdKTy0Mnv"
      },
      "source": [
        "%timeit matrix_add[blocks, threads_per_block](d_a, d_b, d_out, True); cuda.synchronize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Z0WO3j2F0Mnw"
      },
      "source": [
        "result = d_out.copy_to_host()\n",
        "truth = a+b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "smvzVIio0Mnw"
      },
      "source": [
        "np.array_equal(result, truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPRV7EZR0Mnw"
      },
      "source": [
        "**Uncoalesced**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tsCvAmBI0Mnw"
      },
      "source": [
        "%timeit matrix_add[blocks, threads_per_block](d_a, d_b, d_out, False); cuda.synchronize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GaEAgTi_0Mnx"
      },
      "source": [
        "result = d_out.copy_to_host()\n",
        "truth = a+b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "J9SAA83P0Mnx"
      },
      "source": [
        "np.array_equal(result, truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwXlyrZT0Mnx"
      },
      "source": [
        "## Mémoire Partagée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dse3CL4a0Mnx"
      },
      "source": [
        "Jusqu'à présent, nous avons fait la distinction entre la mémoire de l'hôte et celle de la GPU, comme si la mémoire GPU était un seul type de mémoire. Mais en fait, CUDA a une [hiérarchie de mémoire](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy) encore plus fine. La mémoire du dispositif que nous avons utilisée jusqu'à présent est appelée **mémoire globale**, disponible pour n'importe quel thread ou bloc sur l'appareil, et qui peut persister pendant toute la durée de vie de l'application. Naturellement, c'est un espace mémoire relativement grand.\n",
        "\n",
        "Nous allons maintenant discuter de la manière d'utiliser une région de la mémoire appelée **mémoire partagée**. La mémoire partagée est un cache défini par le programmeur, et de taille limitée qui [dépend du GPU](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities). Elle est **partagée** entre tous les threads d'un bloc. Il s'agit d'une ressource rare, à laquelle les threads extérieurs au bloc ne peuvent pas accéder et qui ne persiste pas après la fin de l'exécution d'un noyau. La mémoire partagée a cependant une bande passante beaucoup plus élevée que la mémoire globale et peut être utilisée avec plus d'efficacité dans de nombreux noyaux, en particulier pour optimiser les performances.\n",
        "\n",
        "Voici quelques cas d'utilisation courants de la mémoire partagée :\n",
        "\n",
        "* Mise en cache de la mémoire lue à partir de la mémoire globale qui devra être lue plusieurs fois dans un bloc.\n",
        "* Mise en mémoire tampon de la sortie des threads afin qu'elle puisse être fusionnée (coalescence) avant de la réécrire dans la mémoire globale.\n",
        "* Stockage temporaire de données utilisés dans des opérations gather/scatter dans un bloc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44wmMLl40Mnx"
      },
      "source": [
        "### La syntaxe ppour la mémoire partagée"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rvCoReK0Mnx"
      },
      "source": [
        "Numba fournit des [fonctions](https://numba.pydata.org/numba-doc/dev/cuda/memory.html#shared-memory-and-thread-synchronization) pour l'allocation de mémoire partagée ainsi que pour la synchronisation entre les threads d'un bloc, ce qui est souvent nécessaire après que des threads parallèles ont lu ou écrit dans la mémoire partagée.\n",
        "\n",
        "Lorsque vous déclarez une mémoire partagée, vous fournissez la forme du tableau partagé, ainsi que son type, à l'aide d'un [type Numba](https://numba.pydata.org/numba-doc/dev/reference/types.html#numba-types). **La forme du tableau doit être une valeur constante**, et par conséquent, vous ne pouvez pas utiliser d'arguments passés à la fonction ni des variables fournies comme `numba.cuda.blockDim.x`, ou les valeurs calculées de `cuda.griddim`.\n",
        "\n",
        "Comme ce concepte est un peu plus compliqué, voici un exemple pour démontrer la syntaxe avec des commentaires soulignant le mouvement de la mémoire hôte vers la mémoire globale du dispositif, vers la mémoire partagée, vers la mémoire globale du périphérique et enfin vers la mémoire hôte :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhH49D360Mny"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFzMbDi0Mny"
      },
      "source": [
        "Nous utiliserons `numba.types` pour définir les types de valeurs dans la mémoire partagée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8CpCtKmq0Mny"
      },
      "source": [
        "import numpy as np\n",
        "from numba import types, cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjLTtBxd0Mny"
      },
      "source": [
        "**<Echange (swap) d'éléments avec la mémoire partagée**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VENFAVZZ0Mny"
      },
      "source": [
        "Le noyau suivant prend un vecteur d'entrée, où chaque thread écrira d'abord un élément dans la mémoire partagée puis, après avoir synchronisé de telle sorte que tous les éléments aient été écrits dans la mémoire partagée, écrira un élément de la mémoire partagée dans le vecteur de sortie.\n",
        "\n",
        "Il convient de noter que chaque thread écrira une valeur à partir d'une position de la mémoire partagée, laquelle a été écrite par un autre thread."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xko3UNwG0Mny"
      },
      "source": [
        "@cuda.jit\n",
        "def swap_with_shared(vector, swapped):\n",
        "    # Allocate a 4 element vector containing int32 values in shared memory.\n",
        "    temp = cuda.shared.array(4, dtype=types.int32)\n",
        "\n",
        "    idx = cuda.grid(1)\n",
        "\n",
        "    # Move an element from global memory into shared memory\n",
        "    temp[idx] = vector[idx]\n",
        "\n",
        "    # cuda.syncthreads will force all threads in the block to synchronize here, which is necessary because...\n",
        "    cuda.syncthreads()\n",
        "    #...the following operation is reading an element written to shared memory by another thread.\n",
        "\n",
        "    # Move an element from shared memory back into global memory\n",
        "    swapped[idx] = temp[3 - cuda.threadIdx.x] # swap elements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ-9_3ow0Mny"
      },
      "source": [
        "**Data Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7Mr2lOMY0Mnz"
      },
      "source": [
        "vector = np.arange(4).astype(np.int32)\n",
        "swapped = np.zeros_like(vector)\n",
        "\n",
        "# Move host memory to device (global) memory\n",
        "d_vector = cuda.to_device(vector)\n",
        "d_swapped = cuda.to_device(swapped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "6aLXu-JS0Mnz"
      },
      "source": [
        "vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DPD7p3S0Mnz"
      },
      "source": [
        "**Exécution du Kernel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FxwDr5M70Mnz"
      },
      "source": [
        "swap_with_shared[1, 4](d_vector, d_swapped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St56M2zB0Mnz"
      },
      "source": [
        "**Vérifier les Résultats**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dpICY2U80Mnz"
      },
      "source": [
        "# Move device (global) memory back to the host\n",
        "result = d_swapped.copy_to_host()\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S8GEvKz0Mnz"
      },
      "source": [
        "## Présentation : Mémoire partagée en mode coalescence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKdZZRjl0Mn0"
      },
      "source": [
        "Exécutez la cellule suivante pour charger les diapositives, puis cliquez sur « Démarrer le diaporama » pour les mettre en plein écran."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JNpWnV4L0Mn0"
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame('https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-02-V1/shared_coalescing.pptx', 800, 450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gT6yvrB0Mn0"
      },
      "source": [
        "## Exercice : Utilisation de la mémoire partagée pour les lectures et écritures fusionnées avec transposition de matrice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_uoQDSk0Mn0"
      },
      "source": [
        "Dans cet exercice, vous allez mettre en œuvre ce qui vient d'être démontré dans la présentation en écrivant un noyau pour la transposition d'une matrice qui, en utilisant la mémoire partagée, effectue des lectures et des écritures coalescées dans la matrice de sortie localisée dans la mémoire globale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Nar1Os0Mn0"
      },
      "source": [
        "### Lectures coalescentes, écritures non-coalescentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Zzf6sE0Mn0"
      },
      "source": [
        "À titre de comparaison des performances, voici un noyau de transposition de matrice naïf qui effectue des lectures coalescées à partir de l'entrée, mais des écritures non coalescées vers la sortie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOZH4ME10Mn0"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GxUeJafe0Mn1"
      },
      "source": [
        "from numba import cuda\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2qqSTzg0Mn1"
      },
      "source": [
        "**Data Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6I8hVQ-0Mn1"
      },
      "source": [
        "Ici, nous créons une matrice d'entrée 4096x4096 `a` ainsi qu'une matrice de sortie 4096x4096 `transposée`, et les copions sur l'appareil.\n",
        "\n",
        "Nous définissons également une grille bidimensionnelle avec des blocs bidimensionnels à utiliser ci-dessous. Notez que nous avons créé une grille avec un nombre total de threads égal au nombre d'éléments dans la matrice d'entrée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "A4dvUTyq0Mn1"
      },
      "source": [
        "n = 4096*4096 # 16M\n",
        "\n",
        "# 2D blocks\n",
        "threads_per_block = (32, 32)\n",
        "#2D grid\n",
        "blocks = (128, 128)\n",
        "\n",
        "# 4096x4096 input and output matrices\n",
        "a = np.arange(n).reshape((4096,4096)).astype(np.float32)\n",
        "transposed = np.zeros_like(a).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_transposed = cuda.to_device(transposed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfcahheb0Mn1"
      },
      "source": [
        "**Naive Matrix Transpose Kernel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imgIJyzh0Mn1"
      },
      "source": [
        "Ce noyau transpose correctement « a », en écrivant la transposition dans « transposed ». Il effectue des lectures depuis « a » de manière coalescée, cependant, ses écritures dans « transposed » ne sont pas coalescées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "T7USDX080Mn1"
      },
      "source": [
        "@cuda.jit\n",
        "def transpose(a, transposed):\n",
        "    x, y = cuda.grid(2)\n",
        "\n",
        "    transposed[x][y] = a[y][x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE6C-mU50Mn2"
      },
      "source": [
        "**Check Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bN28INj20Mn2"
      },
      "source": [
        "%timeit transpose[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyye0Iye0Mn2"
      },
      "source": [
        "**Check Correctness**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gMhV_Yar0Mn2"
      },
      "source": [
        "result = d_transposed.copy_to_host()\n",
        "expected = a.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pw_cFWke0Mn2"
      },
      "source": [
        "np.array_equal(result, expected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CxXi3jr0Mn2"
      },
      "source": [
        "### Exercice : réécrire le code pour que les lectures et écritures soient coalescentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVQtAOPX0Mn2"
      },
      "source": [
        "Votre travail consistera à refactoriser le noyau « transpose » pour utiliser la mémoire partagée et effectuer à la fois des lectures et des écritures depuis la mémoire globale de manière fusionnée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTiJpAky0Mn2"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "w0SlRnJA0Mn3"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda, types as numba_types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovwo4JMi0Mn3"
      },
      "source": [
        "**Data Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "WkHRO5Ko0Mn3"
      },
      "source": [
        "n = 4096*4096 # 16M\n",
        "\n",
        "# 2D blocks\n",
        "threads_per_block = (32, 32)\n",
        "#2D grid\n",
        "blocks = (128, 128)\n",
        "\n",
        "# 4096x4096 input and output matrices\n",
        "a = np.arange(n).reshape((4096,4096)).astype(np.float32)\n",
        "transposed = np.zeros_like(a).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_transposed = cuda.to_device(transposed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxjIWxd70Mn3"
      },
      "source": [
        "**Écrire un noyau de transposition qui utilise la mémoire partagée**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSvTbmTZ0Mn3"
      },
      "source": [
        "Complétez les `TODO` dans la définition du noyau `tile_transpose`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ts-KOdVT0Mn3"
      },
      "source": [
        "@cuda.jit\n",
        "def tile_transpose(a, transposed):\n",
        "    # `tile_transpose` assumes it is launched with a 32x32 block dimension,\n",
        "    # and that `a` is a multiple of these dimensions.\n",
        "\n",
        "    # 1) Create 32x32 shared memory array.\n",
        "\n",
        "    # TODO: Your code here.\n",
        "\n",
        "    # Compute offsets into global input array. Recall for coalesced access we want to map threadIdx.x increments to\n",
        "    # the fastest changing index in the data, i.e. the column in our array.\n",
        "    # Note: `a_col` and `a_row` are already correct.\n",
        "    a_col = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    a_row = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "\n",
        "    # 2) Make coalesced read from global memory (using grid indices)\n",
        "    # into shared memory array (using thread indices).\n",
        "\n",
        "    # TODO: Your code here.\n",
        "\n",
        "    # 3) Wait for all threads in the block to finish updating shared memory.\n",
        "\n",
        "    # TODO: Your code here.\n",
        "\n",
        "    # 4) Calculate transposed location for the shared memory array tile\n",
        "    # to be written back to global memory. Note that blockIdx.y*blockDim.y\n",
        "    # and blockIdx.x* blockDim.x are swapped (because we want to write to the\n",
        "    # transpose locations), but we want to keep access coalesced, so match up the\n",
        "    # threadIdx.x to the fastest changing index, i.e. the column./\n",
        "    # Note: `t_col` and `t_row` are already correct.\n",
        "    t_col = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.x\n",
        "    t_row = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.y\n",
        "\n",
        "    # 5) Write from shared memory (using thread indices)\n",
        "    # back to global memory (using grid indices)\n",
        "    # transposing each element within the shared memory array.\n",
        "\n",
        "    # TODO: Your code here."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlIfrROr0Mn4"
      },
      "source": [
        "**Check Performance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8CNWMlg0Mn4"
      },
      "source": [
        "Vérifiez les performances de votre noyau de transposition refactorisé. Vous devriez constater une accélération par rapport aux performances de transposition de base ci-dessus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "I-dA5i0X0Mn4"
      },
      "source": [
        "%timeit tile_transpose[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqv47IKI0Mn4"
      },
      "source": [
        "**Check Correctness**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "1GsR6Y_u0Mn4"
      },
      "source": [
        "result = d_transposed.copy_to_host()\n",
        "expected = a.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "VnbEeyFH0Mn4"
      },
      "source": [
        "np.array_equal(result, expected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InCDnwgs0Mn4"
      },
      "source": [
        "### Pourquoi si peu de gains ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlfwNhul0Mn4"
      },
      "source": [
        "Bien qu'il s'agisse d'une accélération significative pour seulement quelques lignes de code, vous pourriez penser que l'amélioration des performances n'est pas aussi marquée que vous l'espériez par rapport aux expériences précédentes. Il y a deux raisons principales à cela :\n",
        "\n",
        "1. Le noyau de transposition naïf effectuait des lectures fusionnées, donc votre version refactorisée n'a optimisé que la moitié de l'accès à la mémoire globale tout au long de l'exécution du noyau.\n",
        "2. Votre code tel qu'il est écrit souffre de conflits de mémoire partagée, un sujet sur lequel nous allons maintenant porter notre attention.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42jEkFzX0Mn5"
      },
      "source": [
        "## Présentation : Conflits de mémoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3bV4pX90Mn5"
      },
      "source": [
        "Exécutez la cellule suivante pour charger les diapositives, puis cliquez sur « Démarrer le diaporama » pour les mettre en plein écran."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "rA-Fd-8Z0Mn5"
      },
      "source": [
        "from IPython.display import IFrame\n",
        "IFrame('https://view.officeapps.live.com/op/view.aspx?src=https://developer.download.nvidia.com/training/courses/C-AC-02-V1/bank_conflicts.pptx', 800, 450)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJL6U1Mf0Mn5"
      },
      "source": [
        "## Exercice : Résourdre les conflits de mémoire"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be8-quUE0Mn5"
      },
      "source": [
        "En guise d'exercice final, vous refactoriserez le noyau de transposition en utilisant la mémoire partagée pour qu'il soit exempt de conflit de banque de mémoire partagée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH45i_aH0Mn6"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vFnPfMgt0Mn6"
      },
      "source": [
        "import numpy as np\n",
        "from numba import cuda, types as numba_types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1x8xjYU0Mn6"
      },
      "source": [
        "### Data Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "j2HJNvJt0Mn6"
      },
      "source": [
        "n = 4096*4096 # 16M\n",
        "threads_per_block = (32, 32)\n",
        "blocks = (128, 128)\n",
        "\n",
        "a = np.arange(n).reshape((4096,4096)).astype(np.float32)\n",
        "transposed = np.zeros_like(a).astype(np.float32)\n",
        "\n",
        "d_a = cuda.to_device(a)\n",
        "d_transposed = cuda.to_device(transposed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAz79gP_0Mn6"
      },
      "source": [
        "### Rendre le noyau sans conflit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB2hn9kY0Mn6"
      },
      "source": [
        "Le noyau `tile_transpose_conflict_free` est un noyau de transposition de matrice qui utilise la mémoire partagée de sorte que les lectures et les écritures dans la mémoire globale soient fusionnées. Votre travail consiste à refactoriser le noyau afin qu'il ne souffre plus ces conflits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cz-EYhxZ0Mn6"
      },
      "source": [
        "@cuda.jit\n",
        "def tile_transpose_conflict_free(a, transposed):\n",
        "    # `tile_transpose` assumes it is launched with a 32x32 block dimension,\n",
        "    # and that `a` is a multiple of these dimensions.\n",
        "\n",
        "    # 1) Create 32x32 shared memory array.\n",
        "    tile = cuda.shared.array((32, 32), numba_types.int32)\n",
        "\n",
        "    # Compute offsets into global input array.\n",
        "    x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "\n",
        "    # 2) Make coalesced read from global memory into shared memory array.\n",
        "    # Note the use of local thread indices for the shared memory write,\n",
        "    # and global offsets for global memory read.\n",
        "    tile[cuda.threadIdx.y, cuda.threadIdx.x] = a[y, x]\n",
        "\n",
        "    # 3) Wait for all threads in the block to finish updating shared memory.\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # 4) Calculate transposed location for the shared memory array tile\n",
        "    # to be written back to global memory.\n",
        "    t_x = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.x\n",
        "    t_y = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.y\n",
        "\n",
        "    # 5) Write back to global memory,\n",
        "    # transposing each element within the shared memory array.\n",
        "    transposed[t_y, t_x] = tile[cuda.threadIdx.x, cuda.threadIdx.y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxu31CAo0Mn7"
      },
      "source": [
        "### Check Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57KiZFZW0Mn7"
      },
      "source": [
        "En supposant que vous ayez correctement résolu les conflits, ce noyau devrait s'exécuter beaucoup plus rapidement que le noyau de transposition naïf et que le noyau de transposition à mémoire partagée (avec conflits). Pour réussir l'évaluation, votre noyau devra s'exécuter en moyenne en moins de 840 µs.\n",
        "\n",
        "La première valeur imprimée en exécutant la cellule suivante vous donnera le temps d'exécution moyen de votre noyau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "9HI3hGoS0Mn7"
      },
      "source": [
        "%timeit tile_transpose_conflict_free[blocks, threads_per_block](d_a, d_transposed); cuda.synchronize()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}